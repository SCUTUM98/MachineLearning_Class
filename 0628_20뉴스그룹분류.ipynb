{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "news_data = fetch_20newsgroups(subset='all')\n",
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "Name: count, dtype: int64\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(news_data.target).value_counts().sort_index())\n",
    "print(news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: qureshi@bmerh185.bnr.ca (Emran Qureshi)\n",
      "Subject: Re: Europe vs. Muslim Bosnians\n",
      "Organization: Bell-Northern Research, Ottawa, Canada\n",
      "Lines: 26\n",
      "\n",
      "In article <C6x81M.EJF@news.cis.umn.edu> prabhak@giga.cs.umn.edu (Satya Prabhakar) writes:\n",
      ">(mohamed.s.sadek) writes:\n",
      ">>\n",
      ">>I like what Mr. Joseph Biden had to say yesterday 5/11/93 in the senate.\n",
      ">>\n",
      ">>Condemening the european lack of action and lack of support to us plans \n",
      ">>and calling that \"moral rape\".\n",
      ">>\n",
      ">>He went on to say that the reason for that is \"out right religious BIGOTRY\"\n",
      ">\n",
      ">Actually, this strife in Yugoslavia goes back a long way. Bosinan Muslims,\n",
      ">in collaboration with the Nazis, did to Serbians after the first world\n",
      ">war what Serbs are doing to Muslims now. This is not a fresh case of\n",
      ">ethnic cleansing but just another chapter in the continuing saga\n",
      ">of intense mutual hatred, destruction,... Not taking sides in this\n",
      ">perpetual war does not amount to religious bigotry. It could just\n",
      ">be helplessness with regards to bringing peace to a region that does\n",
      ">not even know the meaning of the word.\n",
      ">\n",
      ">Satya Prabhakar\n",
      ">--\n",
      "\n",
      "Yeah right, sorta like the Indian sub-contient, eh?\n",
      "\n",
      "Regards,\n",
      "Emran\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_news.data\n",
    "y_train = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_news.data\n",
    "y_test = test_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기: 11314, 테스트 데이터 크기: 7532\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터 크기: {0}, 테스트 데이터 크기: {1}'.format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(x_train)\n",
    "x_train_cnt_vect = cnt_vect.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cnt_vect = cnt_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer shape:  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizer shape: ', x_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression: 0.617\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(x_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(x_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression: {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6736590546999469\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer()\n",
    "tv.fit(x_train)\n",
    "x_train_tv = tv.transform(x_train)\n",
    "x_test_tv = tv.transform(x_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_tv,y_train)\n",
    "pred = model.predict(x_test_tv)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_test, y_test)\n",
    "\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(x_train)\n",
    "x_train_cnt_vect = cnt_vect.transform(x_train)\n",
    "x_test_cnt_vect = cnt_vect.transform(x_test)\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(x_train_cnt_vect, y_train)\n",
    "pred = lr_clf.predict(x_test_cnt_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer()\n",
    "tv.fit(x_train)\n",
    "x_train_tv = tv.transform(x_train)\n",
    "x_test_tv = tv.transform(x_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_tv,y_train)\n",
    "pred = model.predict(x_test_tv)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "params = {'C':[0.001,0.01,0.1,1,5,10]}\n",
    "model = LogisticRegression()\n",
    "gs = GridSearchCV(model,param_grid = params,cv=5,scoring='accuracy')\n",
    "gs.fit(x_train_tv,y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6845459373340415\n"
     ]
    }
   ],
   "source": [
    "pred = gs.predict(x_test_tv)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7010090281465746\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tv = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
    "tv.fit(x_train)\n",
    "x_train_tv = tv.transform(x_train)\n",
    "x_test_tv = tv.transform(x_test)\n",
    "\n",
    "model = LogisticRegression(C=10)\n",
    "model.fit(x_train_tv,y_train)\n",
    "pred = model.predict(x_test_tv)\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 사용 및 GridsearchCV 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Pipeline: 0.704\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
    "                    ('lr_clf', LogisticRegression(solver='liblinear', C=10))])\n",
    "pipeline.fit(x_train, y_train)\n",
    "pred = pipeline.predict(x_test)\n",
    "print('Logistic Regression with Pipeline: {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
